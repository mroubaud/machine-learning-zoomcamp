{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "156a6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "73232cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defino las dimensiones de las imagenes inputs\n",
    "inputs = keras.Input(shape=(150,150,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "027b63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo modelo como secuencia de capaz (layers)\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0b5b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrego convlayer. la salida son 32 imagenes de (150,150,3)/(3,3,3), una por cada filtro\n",
    "#el tamaño de los filtros es de 3x3\n",
    "#uso relu como función de activación \n",
    "model.add(layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size =(3,3),\n",
    "    input_shape = (150,150,3),\n",
    "    activation='relu'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "259f3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling: hago pooling pasando de una imagen de (150,150,3)/(3,3,3) a (150,150,3)/(3,3,3)/(2,2,3)\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ee71d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten: Paso de matriz a vector de imagen\n",
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "019b0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrego denselayer de 60 outputs y activation function relu (es la mas usada)\n",
    "model.add(layers.Dense(60, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4f4420d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agrego denselayer de 1 outputs y activation function relu (es la mas usada)\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d285dfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "#Compilo mi modelo\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.SGD(learning_rate=0.002, momentum=0.8),\n",
    "             metrics=['acc'])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8a4be54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#defino mi grupo de imagenes de entrenamiento, le asigno una funcion de pre preocesamiento\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "#Le asigno imagenes que voy a usar para entrenar denselayer, el tamaño de las imagenes y la cantidad de imagenes por batch\n",
    "train_ds = train_gen.flow_from_directory(\"./data/train/\", target_size=(150,150), batch_size=20,shuffle=True, class_mode='binary')\n",
    "\n",
    "#cargo test data\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_ds = test_gen.flow_from_directory('./data/test/',target_size=(150,150),batch_size=20,shuffle=True,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "59ed9ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:13:11.364137: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - ETA: 0s - loss: 0.6922 - acc: 0.5290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:13:22.292400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 12s 64ms/step - loss: 0.6922 - acc: 0.5290 - val_loss: 0.6852 - val_acc: 0.5392\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 12s 65ms/step - loss: 0.6796 - acc: 0.5543 - val_loss: 0.6504 - val_acc: 0.5882\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 12s 66ms/step - loss: 0.6483 - acc: 0.6244 - val_loss: 0.6098 - val_acc: 0.6710\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 12s 63ms/step - loss: 0.6161 - acc: 0.6492 - val_loss: 0.5873 - val_acc: 0.6786\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 11s 62ms/step - loss: 0.5752 - acc: 0.7003 - val_loss: 0.5485 - val_acc: 0.7331\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 11s 62ms/step - loss: 0.5328 - acc: 0.7346 - val_loss: 0.5482 - val_acc: 0.7266\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 11s 61ms/step - loss: 0.5039 - acc: 0.7661 - val_loss: 0.5368 - val_acc: 0.7320\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 11s 62ms/step - loss: 0.4778 - acc: 0.7762 - val_loss: 0.5191 - val_acc: 0.7571\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 11s 62ms/step - loss: 0.4566 - acc: 0.7944 - val_loss: 0.5119 - val_acc: 0.7582\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 11s 61ms/step - loss: 0.4327 - acc: 0.8126 - val_loss: 0.5062 - val_acc: 0.7549\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b6b1b340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x16d5d1190>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0338d221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 60)                10513980  \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,514,937\n",
      "Trainable params: 10,514,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###Question 1\n",
    "#Since we have a binary classification problem, what is the best loss function for us? -> binary crossentropy\n",
    "\n",
    "#mean squared error\n",
    "#binary crossentropy\n",
    "#categorical crossentropy\n",
    "#cosine similarity\n",
    "\n",
    "\n",
    "###Question 2\n",
    "#What's the number of parameters in the convolutional layer of our model? You can use the summary method for that. \n",
    "# -> 896\n",
    "\n",
    "#1\n",
    "#65\n",
    "#896\n",
    "#11214912\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2894c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5289638042449951, 0.5542562007904053, 0.6244220733642578, 0.6491705179214478, 0.7002991437911987, 0.7345662117004395, 0.7661136984825134, 0.7761762142181396, 0.7943975925445557, 0.8126189708709717]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7174326777458191"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Question 3\n",
    "#What is the median of training accuracy for all the epochs for this model?->0.8\n",
    "\n",
    "#0.20\n",
    "#0.40\n",
    "#0.60\n",
    "#0.80\n",
    "\n",
    "print(history.history[\"acc\"])\n",
    "np.median(history.history[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0629c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6921809911727905, 0.6795583367347717, 0.6482657790184021, 0.616052508354187, 0.5752443671226501, 0.532848060131073, 0.503947913646698, 0.4778006970882416, 0.4565884470939636, 0.4326738715171814]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0896938285848629"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 4\n",
    "#What is the standard deviation of training loss for all the epochs for this model? ->0.091\n",
    "\n",
    "#0.031\n",
    "#0.061\n",
    "#0.091\n",
    "#0.131\n",
    "\n",
    "print(history.history[\"loss\"])\n",
    "np.std(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1e5abace",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1400c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3677 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#defino mi grupo de imagenes de entrenamiento, le asigno una funcion de pre preocesamiento\n",
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "#Le asigno imagenes que voy a usar para entrenar denselayer, el tamaño de las imagenes y la cantidad de imagenes por batch\n",
    "train_ds = train_gen.flow_from_directory(\"./data/train/\", target_size=(150,150), batch_size=20,shuffle=True, \n",
    "                                         class_mode='binary')\n",
    "\n",
    "#cargo test data\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_ds = test_gen.flow_from_directory('./data/test/',target_size=(150,150),batch_size=20,shuffle=True,\n",
    "                                       class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6cf1c62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x16d5d1190>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "56b962d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 10, 'steps': 184}\n"
     ]
    }
   ],
   "source": [
    "print(history.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4bf003e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:35:32.561508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - ETA: 0s - loss: 0.0215 - acc: 0.9976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 18:35:43.992738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 13s 69ms/step - loss: 0.0215 - acc: 0.9976 - val_loss: 0.8445 - val_acc: 0.7593\n",
      "Epoch 2/20\n",
      "184/184 [==============================] - 13s 70ms/step - loss: 0.0164 - acc: 0.9978 - val_loss: 0.9467 - val_acc: 0.7418\n",
      "Epoch 3/20\n",
      "184/184 [==============================] - 12s 68ms/step - loss: 0.0165 - acc: 0.9984 - val_loss: 0.9011 - val_acc: 0.7680\n",
      "Epoch 4/20\n",
      "184/184 [==============================] - 12s 66ms/step - loss: 0.0251 - acc: 0.9956 - val_loss: 0.8925 - val_acc: 0.7636\n",
      "Epoch 5/20\n",
      "184/184 [==============================] - 13s 68ms/step - loss: 0.0202 - acc: 0.9970 - val_loss: 0.8242 - val_acc: 0.7658\n",
      "Epoch 6/20\n",
      "184/184 [==============================] - 12s 65ms/step - loss: 0.0155 - acc: 0.9984 - val_loss: 0.9906 - val_acc: 0.7582\n",
      "Epoch 7/20\n",
      "184/184 [==============================] - 12s 63ms/step - loss: 0.0117 - acc: 0.9986 - val_loss: 0.9161 - val_acc: 0.7636\n",
      "Epoch 8/20\n",
      "184/184 [==============================] - 12s 64ms/step - loss: 0.0099 - acc: 0.9992 - val_loss: 0.8950 - val_acc: 0.7723\n",
      "Epoch 9/20\n",
      "184/184 [==============================] - 12s 64ms/step - loss: 0.0121 - acc: 0.9989 - val_loss: 0.9184 - val_acc: 0.7800\n",
      "Epoch 10/20\n",
      "184/184 [==============================] - 12s 63ms/step - loss: 0.0083 - acc: 0.9992 - val_loss: 1.0631 - val_acc: 0.7538\n",
      "Epoch 11/20\n",
      "184/184 [==============================] - 12s 63ms/step - loss: 0.0130 - acc: 0.9986 - val_loss: 0.9947 - val_acc: 0.7636\n",
      "Epoch 12/20\n",
      "184/184 [==============================] - 12s 63ms/step - loss: 0.0085 - acc: 0.9992 - val_loss: 0.9782 - val_acc: 0.7647\n",
      "Epoch 13/20\n",
      "184/184 [==============================] - 12s 66ms/step - loss: 0.0094 - acc: 0.9992 - val_loss: 0.9964 - val_acc: 0.7603\n",
      "Epoch 14/20\n",
      "184/184 [==============================] - 12s 62ms/step - loss: 0.0077 - acc: 0.9989 - val_loss: 0.9732 - val_acc: 0.7647\n",
      "Epoch 15/20\n",
      "184/184 [==============================] - 12s 64ms/step - loss: 0.0106 - acc: 0.9981 - val_loss: 0.9606 - val_acc: 0.7614\n",
      "Epoch 16/20\n",
      "184/184 [==============================] - 12s 67ms/step - loss: 0.0068 - acc: 0.9992 - val_loss: 0.9966 - val_acc: 0.7669\n",
      "Epoch 17/20\n",
      "184/184 [==============================] - 13s 69ms/step - loss: 0.0071 - acc: 0.9992 - val_loss: 0.9877 - val_acc: 0.7603\n",
      "Epoch 18/20\n",
      "184/184 [==============================] - 13s 69ms/step - loss: 0.0071 - acc: 0.9995 - val_loss: 0.9684 - val_acc: 0.7734\n",
      "Epoch 19/20\n",
      "184/184 [==============================] - 12s 64ms/step - loss: 0.0077 - acc: 0.9986 - val_loss: 0.9846 - val_acc: 0.7756\n",
      "Epoch 20/20\n",
      "184/184 [==============================] - 12s 64ms/step - loss: 0.0075 - acc: 0.9989 - val_loss: 1.2652 - val_acc: 0.7516\n"
     ]
    }
   ],
   "source": [
    "history_2 = model.fit(train_ds, epochs=20, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "87c03288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8444859385490417, 0.9466586112976074, 0.9011085033416748, 0.8924510478973389, 0.8241760730743408, 0.9906443357467651, 0.9161298274993896, 0.8950350284576416, 0.9183586239814758, 1.0631365776062012, 0.9947185516357422, 0.9781528115272522, 0.9963799715042114, 0.9731993079185486, 0.960608184337616, 0.9965753555297852, 0.9876878261566162, 0.9683721661567688, 0.9845952987670898, 1.2652326822280884]\n"
     ]
    }
   ],
   "source": [
    "###Question 5\n",
    "#Let's train our model for 10 more epochs using the same code as previously.\n",
    "#Note: make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "#What is the mean of test loss for all the epochs for the model trained with augmentations?->0.67->0.78\n",
    "#0.18\n",
    "#0.48\n",
    "#0.78\n",
    "#0.108\n",
    "print(history_2.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "21c0e2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9648853361606597"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history_2.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2ddbf80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.02152210846543312,\n",
       "  0.01644996739923954,\n",
       "  0.01651930622756481,\n",
       "  0.025129806250333786,\n",
       "  0.02018633857369423,\n",
       "  0.01549452729523182,\n",
       "  0.01171056367456913,\n",
       "  0.00991904642432928,\n",
       "  0.01206317637115717,\n",
       "  0.008306118659675121,\n",
       "  0.012992841191589832,\n",
       "  0.008516942150890827,\n",
       "  0.009398664347827435,\n",
       "  0.0077408794313669205,\n",
       "  0.010630414821207523,\n",
       "  0.006833379156887531,\n",
       "  0.007072297856211662,\n",
       "  0.007051982916891575,\n",
       "  0.00766519270837307,\n",
       "  0.007548456080257893],\n",
       " 'acc': [0.9975523352622986,\n",
       "  0.9978243112564087,\n",
       "  0.9983682632446289,\n",
       "  0.9956486225128174,\n",
       "  0.9970084428787231,\n",
       "  0.9983682632446289,\n",
       "  0.9986401796340942,\n",
       "  0.9991841316223145,\n",
       "  0.9989121556282043,\n",
       "  0.9991841316223145,\n",
       "  0.9986401796340942,\n",
       "  0.9991841316223145,\n",
       "  0.9991841316223145,\n",
       "  0.9989121556282043,\n",
       "  0.9980962872505188,\n",
       "  0.9991841316223145,\n",
       "  0.9991841316223145,\n",
       "  0.9994561076164246,\n",
       "  0.9986401796340942,\n",
       "  0.9989121556282043],\n",
       " 'val_loss': [0.8444859385490417,\n",
       "  0.9466586112976074,\n",
       "  0.9011085033416748,\n",
       "  0.8924510478973389,\n",
       "  0.8241760730743408,\n",
       "  0.9906443357467651,\n",
       "  0.9161298274993896,\n",
       "  0.8950350284576416,\n",
       "  0.9183586239814758,\n",
       "  1.0631365776062012,\n",
       "  0.9947185516357422,\n",
       "  0.9781528115272522,\n",
       "  0.9963799715042114,\n",
       "  0.9731993079185486,\n",
       "  0.960608184337616,\n",
       "  0.9965753555297852,\n",
       "  0.9876878261566162,\n",
       "  0.9683721661567688,\n",
       "  0.9845952987670898,\n",
       "  1.2652326822280884],\n",
       " 'val_acc': [0.7592592835426331,\n",
       "  0.741830050945282,\n",
       "  0.7679738402366638,\n",
       "  0.7636165618896484,\n",
       "  0.7657952308654785,\n",
       "  0.758169949054718,\n",
       "  0.7636165618896484,\n",
       "  0.772331178188324,\n",
       "  0.7799564003944397,\n",
       "  0.7538126111030579,\n",
       "  0.7636165618896484,\n",
       "  0.7647058963775635,\n",
       "  0.7603485584259033,\n",
       "  0.7647058963775635,\n",
       "  0.7614378929138184,\n",
       "  0.7668845057487488,\n",
       "  0.7603485584259033,\n",
       "  0.7734204530715942,\n",
       "  0.7755991220474243,\n",
       "  0.7516340017318726]}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "96a19a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675381064414978"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Question 6\n",
    "#What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "#->0.75->0.78\n",
    "#0.38\n",
    "#0.58\n",
    "#0.78\n",
    "#0.98\n",
    "np.mean(history_2.history[\"val_acc\"][-6:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea75bccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
